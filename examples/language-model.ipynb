{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from shiba import Trainer\n",
    "from shiba.steps import rnn_step, rnn_eval_step\n",
    "from shiba.callbacks import LambdaCallback, TensorBoard, Metric, Save\n",
    "from shiba.utils import model_summary\n",
    "\n",
    "from data import Corpus, LMLoader\n",
    "from model import LSTMLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 s, sys: 97.4 ms, total: 21.8 s\n",
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "%time corpus = Corpus(path='data/wikitext-2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = corpus.train\n",
    "valid_data = corpus.valid\n",
    "test_data = corpus.test\n",
    "i2w = corpus.dictionary.idx2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(corpus.dictionary) # num unique tokens in dictionary, 33278\n",
    "batch_size = 32\n",
    "eval_batch_size = 12\n",
    "seq_len = 35 # sometimes called back prop through time (bptt) length during training.\n",
    "variable_length = True\n",
    "\n",
    "embedding_size = 10\n",
    "hidden_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = LMLoader(train_data, batch_size=batch_size, seq_len=seq_len, variable_length=variable_length)\n",
    "valid_loader = LMLoader(valid_data, batch_size=eval_batch_size, seq_len=seq_len, variable_length=variable_length)\n",
    "test_data = LMLoader(test_data, batch_size=eval_batch_size, seq_len=seq_len, variable_length=variable_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['(', '<unk>', ')', '.', 'The', 'partnership', 'for', 'the',\n",
       "       'Europa', 'Jupiter', 'System', 'Mission', 'has', 'since', 'ended',\n",
       "       ',', 'but', 'NASA', 'will', 'continue', 'to', 'contribute', 'the',\n",
       "       'European', 'mission'], dtype='<U11')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, targets = next(train_loader)\n",
    "np.array([i2w[i] for i in inputs[:, 10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMLM(vocab_size=vocab_size, embedding_size=10, hidden_size=20, nlayers=2, dropout=0.5)\n",
    "hidden = model.init_hidden(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Name    | Output Size             | Parameters   |\n",
       "|:--------|:------------------------|:-------------|\n",
       "| drop    | (25, 32, 10)            | 0            |\n",
       "| encoder | (25, 32, 10)            | 332,780      |\n",
       "| lstm    | [(32, 20), (2, 32, 20)] | 5,920        |\n",
       "| decoder | (25, 32, 33278)         | 698,838      |\n",
       "| TOTAL:  | -----------------       | 1,037,538    |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_summary(model, inputs, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "trainer = Trainer(model, criterion, train_step=rnn_step, eval_step=rnn_eval_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_grad_norm(trainer, max_norm=0.25):\n",
    "    torch.nn.utils.clip_grad_norm_(trainer.model.parameters(), max_norm)\n",
    "\n",
    "def perpexity(loss):\n",
    "    # exp of cross entropy loss\n",
    "    return math.exp(loss)\n",
    "    \n",
    "callbacks = [TensorBoard(log_dir='runs/shiba-test-lm'),\n",
    "             Metric('perpexity', \n",
    "                    score_func=perpexity,\n",
    "                    transform=lambda x: x['loss'].item()),\n",
    "             Save('weights/test-lm', monitor='val_perpexity'),\n",
    "#              LambdaCallback(on_batch_end=clip_grad_norm)\n",
    "            ]\n",
    "!rm -rf runs/shiba-test-lm # clear tb logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30bdf5745a9840eba7f1fd369adedd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f06efff306e49faac9aac0e98a32083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1764), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.find_lr(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit_one_cycle(train_loader, valid_loader, epochs=4, max_lr=5e-2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
